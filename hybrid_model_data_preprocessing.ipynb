{"cells":[{"cell_type":"markdown","metadata":{"id":"3yEtUSx-PoVS"},"source":["# Data Preprocessing for hybrid model"]},{"cell_type":"markdown","metadata":{"id":"8HwgFzWaPtmp"},"source":["This notebook uses the `sumy` sdk to preprocess the judgement data based on extractive models.\n","\n","The preprocessing step will shorten the judgement from over 16k(?) words into 500 sentenes which will then be used as input for the abstractive model. With this preprocessing step, we will be able to cut the inference time by a lot.\n","\n","The extractive model being used here is LsaSummarizer. It uses Latent Semantic Analysis (LSA) to extract the most important sentences from a document. LSA is a widely-used technique in natural language processing that identifies hidden patterns in text data by analyzing the relationships between words and documents.\n","https://reintech.io/blog/how-to-create-a-text-summarization-tool-with-sumy-tutorial-for-developers\n","\n","We think this will be helpful for legal documents like judgements, since the judgements usually inexplicitly contains structures like evidence, case, issues, analysis, decisions, etc.\n"]},{"cell_type":"markdown","metadata":{"id":"AN_bXX543FKA"},"source":["# Connect to Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":982,"status":"ok","timestamp":1690691307619,"user":{"displayName":"Brian Tung","userId":"02910268886602075455"},"user_tz":420},"id":"nPxNcHrHC8iS","outputId":"4130e964-ab40-4005-869e-152ce16488a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"QcbH2rFn59Cf"},"source":["# Read in Train and Test data directly from csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bIWR5Jq5yrX"},"outputs":[],"source":["# Read in CSV data\n","import pandas as pd\n","train_df = pd.read_csv(\"/content/drive/MyDrive/W266 Final Project/data/train_data.csv\")\n","train_df_filter = train_df[['index', 'judgement','summary']]\n","test_df = pd.read_csv(\"/content/drive/MyDrive/W266 Final Project/data/test_data.csv\")\n","test_df_filter = test_df[['index', 'judgement','summary']]"]},{"cell_type":"markdown","source":["# Randomly Select 1000 Records from train_data_LSA_extractive_500.csv\n"],"metadata":{"id":"_gLsau7HwAUD"}},{"cell_type":"code","source":["import pandas as pd\n","train_data = pd.read_csv(\"/content/drive/My Drive/W266 Final Project/output/train_data_LSA_extractive_500.csv\")\n","train_data = train_data.dropna()\n","# # Check for zero nan values in df\n","# sum(train_data['Summary'].isnull())\n","train_data1000 = train_data.sample(n=1000, random_state=42)\n","train_data1000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"5JAPOH06wHjU","executionInfo":{"status":"ok","timestamp":1690691322623,"user_tz":420,"elapsed":7126,"user":{"displayName":"Brian Tung","userId":"02910268886602075455"}},"outputId":"4362b4fb-b2c1-4821-96fa-a4da3083c1f2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   Index                                            Summary  \\\n","7257            4809.txt  The first respondent joined M.B.B.S. course of...   \n","4353             543.txt  On the death of R, a Hindu jat, in April or Ma...   \n","4072             372.txt  An application was filed by the first responde...   \n","132   uksc-2010-0177.txt  Scottish Widows Plc (Scottish Widows) is a lif...   \n","7505            6391.txt  The appellant and the respondents applied for ...   \n","...                  ...                                                ...   \n","7028             329.txt  The exercise of the power conferred on the Reg...   \n","3682            1148.txt  The Government of Jammu and Kashmir on the bas...   \n","3437            5900.txt  The respondent company manufactures ossein and...   \n","4105            3856.txt  Respondents are the ex proprietors, and occupa...   \n","6587            6948.txt  The appellant 's father let out the disputed b...   \n","\n","                                      ExtractiveSummary  \n","7257  Civil Appeal No. 2828 of 1977. Appeal by Speci...  \n","4353  Civil Appeal No. 137 of 1953. Appeal from the ...  \n","4072  Appeal No. 312 of 1955. On appeal by special l...  \n","132   This is an appeal from an interlocutor of the ...  \n","7505  vil Appeal Nos. 16 16 17 of 1990. From the Jud...  \n","...                                                 ...  \n","7028  Civil Appeal No. 116 of 1953. Appeal from the ...  \n","3682  Appeal No. 31 of 1957. Appeal from the judgmen...  \n","3437  n that the products must contain visible piece...  \n","4105  CIVIL Appeal No 2475 of 1968. From the Judgmen...  \n","6587  ivil Appeal No. 1945 of 1992. From the Judgmen...  \n","\n","[1000 rows x 3 columns]"],"text/html":["\n","\n","  <div id=\"df-468c5efc-07b9-4ec9-90f6-46cba52743c6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Index</th>\n","      <th>Summary</th>\n","      <th>ExtractiveSummary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7257</th>\n","      <td>4809.txt</td>\n","      <td>The first respondent joined M.B.B.S. course of...</td>\n","      <td>Civil Appeal No. 2828 of 1977. Appeal by Speci...</td>\n","    </tr>\n","    <tr>\n","      <th>4353</th>\n","      <td>543.txt</td>\n","      <td>On the death of R, a Hindu jat, in April or Ma...</td>\n","      <td>Civil Appeal No. 137 of 1953. Appeal from the ...</td>\n","    </tr>\n","    <tr>\n","      <th>4072</th>\n","      <td>372.txt</td>\n","      <td>An application was filed by the first responde...</td>\n","      <td>Appeal No. 312 of 1955. On appeal by special l...</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>uksc-2010-0177.txt</td>\n","      <td>Scottish Widows Plc (Scottish Widows) is a lif...</td>\n","      <td>This is an appeal from an interlocutor of the ...</td>\n","    </tr>\n","    <tr>\n","      <th>7505</th>\n","      <td>6391.txt</td>\n","      <td>The appellant and the respondents applied for ...</td>\n","      <td>vil Appeal Nos. 16 16 17 of 1990. From the Jud...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7028</th>\n","      <td>329.txt</td>\n","      <td>The exercise of the power conferred on the Reg...</td>\n","      <td>Civil Appeal No. 116 of 1953. Appeal from the ...</td>\n","    </tr>\n","    <tr>\n","      <th>3682</th>\n","      <td>1148.txt</td>\n","      <td>The Government of Jammu and Kashmir on the bas...</td>\n","      <td>Appeal No. 31 of 1957. Appeal from the judgmen...</td>\n","    </tr>\n","    <tr>\n","      <th>3437</th>\n","      <td>5900.txt</td>\n","      <td>The respondent company manufactures ossein and...</td>\n","      <td>n that the products must contain visible piece...</td>\n","    </tr>\n","    <tr>\n","      <th>4105</th>\n","      <td>3856.txt</td>\n","      <td>Respondents are the ex proprietors, and occupa...</td>\n","      <td>CIVIL Appeal No 2475 of 1968. From the Judgmen...</td>\n","    </tr>\n","    <tr>\n","      <th>6587</th>\n","      <td>6948.txt</td>\n","      <td>The appellant 's father let out the disputed b...</td>\n","      <td>ivil Appeal No. 1945 of 1992. From the Judgmen...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-468c5efc-07b9-4ec9-90f6-46cba52743c6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-50b18c6b-8836-42f7-8bfa-36086411bc6a\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50b18c6b-8836-42f7-8bfa-36086411bc6a')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-50b18c6b-8836-42f7-8bfa-36086411bc6a button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-468c5efc-07b9-4ec9-90f6-46cba52743c6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-468c5efc-07b9-4ec9-90f6-46cba52743c6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["import csv\n","\n","output_file_path = f'/content/drive/MyDrive/W266 Final Project/output/train_data_1000.csv'\n","\n","train_data1000.to_csv(output_file_path, index=False)"],"metadata":{"id":"soc8plnPxg_F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_data1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7XY8dwIz7Zo","executionInfo":{"status":"ok","timestamp":1690691341978,"user_tz":420,"elapsed":3,"user":{"displayName":"Brian Tung","userId":"02910268886602075455"}},"outputId":"e6eff839-066f-4be3-932a-251f4afdfb1c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":[],"metadata":{"id":"xKisuDTvz7UA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IfyVelI5wFWK"},"source":["# Setup Sumy"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26567,"status":"ok","timestamp":1690597438193,"user":{"displayName":"Lainka Zhu","userId":"15676904741700217180"},"user_tz":420},"id":"mO7Mv36zwHCC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f519a553-173f-4f28-8d11-e22c074e2b7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sumy\n","  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docopt<0.7,>=0.6.1 (from sumy)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting breadability>=0.1.20 (from sumy)\n","  Downloading breadability-0.1.20.tar.gz (32 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.27.1)\n","Collecting pycountry>=18.2.23 (from sumy)\n","  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n","Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.0.0)\n","Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.3.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.65.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pycountry>=18.2.23->sumy) (67.7.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4)\n","Building wheels for collected packages: breadability, docopt, pycountry\n","  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21693 sha256=ac609f3ff91d2a88f306e90494754ebc7fe60ac9caf818b830be3a2274dc7ed8\n","  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=945713ca7b50363a5ea982bcbb5f991d717ece51aa3cf426c938565c17253e5e\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","  Building wheel for pycountry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681831 sha256=603c27f47de4c73a3b7922c6625b76ea9c88867755f38e2dc83b18742556e00c\n","  Stored in directory: /root/.cache/pip/wheels/03/57/cc/290c5252ec97a6d78d36479a3c5e5ecc76318afcb241ad9dbe\n","Successfully built breadability docopt pycountry\n","Installing collected packages: docopt, pycountry, breadability, sumy\n","Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-22.3.5 sumy-0.11.0\n"]}],"source":["!pip install sumy"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3461,"status":"ok","timestamp":1690597441645,"user":{"displayName":"Lainka Zhu","userId":"15676904741700217180"},"user_tz":420},"id":"QERI7ZMOwUP-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"afd684b6-a465-4158-98c0-00f6da04eb8f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}],"source":["import nltk\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{"id":"NPlmHSLfDCap"},"source":["# Generate extactive summary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6P02OL3hZ6Ss"},"outputs":[],"source":["NUM_SENTENCES = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vDVlUBLkwI64","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a976cd5b-cedd-4d3d-c4a3-f2c0a089c3c6","executionInfo":{"status":"ok","timestamp":1690614547509,"user_tz":420,"elapsed":4684120,"user":{"displayName":"Lainka Zhu","userId":"15676904741700217180"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["train dataset length: 7723\n","Summarization generated for: 7723\n"]}],"source":["from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer\n","from sumy.summarizers.lsa import LsaSummarizer\n","\n","# Initialize the summarizer with the LsaSummarizer algorithm\n","summarizer = LsaSummarizer()\n","\n","output = []\n","\n","print(\"train dataset length:\", len(train_df_filter))\n","\n","for judgement in train_df_filter['judgement']:\n","  parser = PlaintextParser.from_string(judgement, Tokenizer(\"english\"))\n","\n","  # Summarize the article and get the most important sentences\n","  summary = summarizer(parser.document, NUM_SENTENCES)  # You can change the number of sentences as needed\n","  summary_sentences = \" \".join([str(sentence) for sentence in summary])\n","  output.append(summary_sentences)\n","\n","print(\"Summarization generated for:\", len(output))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e-jUqXvJ-D1z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690614553115,"user_tz":420,"elapsed":5614,"user":{"displayName":"Lainka Zhu","userId":"15676904741700217180"}},"outputId":"171f995a-f55e-43d4-c3ad-69b722ac26ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Summary sentences written to: /content/drive/MyDrive/W266 Final Project/output/train_data_LSA_extractive_100.csv\n"]}],"source":["import csv\n","\n","output_file_path = f'/content/drive/MyDrive/W266 Final Project/output/train_data_LSA_extractive_{NUM_SENTENCES}.csv'\n","\n","with open(output_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n","    # Create a CSV writer object\n","    csv_writer = csv.writer(csvfile)\n","\n","    # Write the header row (optional, if you want to include column headers)\n","    csv_writer.writerow(['Index', 'Summary', 'ExtractiveSummary'])\n","\n","    # Write the data rows (judgement and its corresponding summary)\n","    for i in range(len(output)):\n","        # Write the judgement and its summary to the CSV file\n","        csv_writer.writerow([train_df_filter[\"index\"][i], train_df_filter['summary'][i], output[i]])\n","\n","print(\"Summary sentences written to:\", output_file_path)"]},{"cell_type":"markdown","source":["# Count average number of words"],"metadata":{"id":"QBSbMtjoMiYK"}},{"cell_type":"code","source":["import pandas as pd\n","extractive = pd.read_csv(f\"/content/drive/MyDrive/W266 Final Project/output/train_data_LSA_extractive_{NUM_SENTENCES}.csv\")\n","extractive = extractive[['Index', 'ExtractiveSummary']]"],"metadata":{"id":"WdCBxd-YGL_I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["words_list = extractive['ExtractiveSummary'][0].split()\n","print(len(words_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ncvq65H4fO2Y","executionInfo":{"status":"ok","timestamp":1690614556070,"user_tz":420,"elapsed":11,"user":{"displayName":"Lainka Zhu","userId":"15676904741700217180"}},"outputId":"7538150f-16de-4674-8e73-5a5a99a5f100"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3415\n"]}]},{"cell_type":"code","source":["total_word_count = 0\n","\n","for summary in extractive['ExtractiveSummary']:\n","  word_count = len(summary.split())\n","  total_word_count += word_count\n","\n","print(total_word_count)\n","print(len(extractive))\n","print(total_word_count / len(extractive))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xe9zsNtpfsQg","executionInfo":{"status":"ok","timestamp":1690614557268,"user_tz":420,"elapsed":1205,"user":{"displayName":"Lainka Zhu","userId":"15676904741700217180"}},"outputId":"97575cfb-b372-4eb9-e392-b426ff08177d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["20350581\n","7723\n","2635.0616340800207\n"]}]},{"cell_type":"markdown","source":["# Hybrid Model (100-sentence) Evaluation"],"metadata":{"id":"cgydtSV86lAK"}},{"cell_type":"code","source":["import pandas as pd\n","extractive = pd.read_csv(f\"/content/drive/MyDrive/W266 Final Project/output/train_data_LSA_extractive_{NUM_SENTENCES}.csv\")\n","extractive = extractive[['Index', 'Summary', 'ExtractiveSummary']]"],"metadata":{"id":"-Rtyz9SZ6olE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q evaluate\n","!pip install rouge_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yx4QlJ22645n","executionInfo":{"status":"ok","timestamp":1690672315229,"user_tz":420,"elapsed":18407,"user":{"displayName":"Lainka Zhu","userId":"15676904741700217180"}},"outputId":"c5d85563-edf0-4f26-a18d-fbc5fc6d77f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.4/492.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.22.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=6d9d6003dd304c50342943e0698cf19b6e8ef4d8250e025cd1b6c67b1ea5e393\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}]},{"cell_type":"code","source":["import evaluate\n","rouge = evaluate.load('rouge')\n","results = rouge.compute(predictions=extractive[\"ExtractiveSummary\"],\n","                        references=extractive[\"Summary\"])\n","print(results)"],"metadata":{"id":"kVN5KfYn7CQ5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aQaYC-i_ZyYA"},"source":["# Archived"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12171,"status":"ok","timestamp":1690257883807,"user":{"displayName":"Lainka Zhu","userId":"15676904741700217180"},"user_tz":420},"id":"aLYoePb9S-7o","outputId":"18886d66-2043-4a62-9ad0-91aeac48611c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Summary sentences written to: /content/drive/MyDrive/W266 Final Project/output/train_data_LSA_extractive_500.csv\n"]}],"source":["# rename column\n","\n","import pandas as pd\n","output = pd.read_csv(\"/content/drive/MyDrive/W266 Final Project/output/train_data_LSA_extractive_500_old.csv\")\n","output = output['BaselineSummary']\n","\n","\n","import csv\n","\n","output_file_path = '/content/drive/MyDrive/W266 Final Project/output/train_data_LSA_extractive_500.csv'\n","\n","with open(output_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n","    # Create a CSV writer object\n","    csv_writer = csv.writer(csvfile)\n","\n","    # Write the header row (optional, if you want to include column headers)\n","    csv_writer.writerow(['Index', 'Summary', 'ExtractiveSummary'])\n","\n","    # Write the data rows (judgement and its corresponding summary)\n","    for i in range(len(output)):\n","        # Write the judgement and its summary to the CSV file\n","        csv_writer.writerow([train_df_filter[\"index\"][i], train_df_filter['summary'][i], output[i]])\n","\n","print(\"Summary sentences written to:\", output_file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-RNKo62M_TW"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["aQaYC-i_ZyYA"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}